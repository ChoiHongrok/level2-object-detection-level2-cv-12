{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmcv import Config\n",
    "from mmdet.datasets import build_dataset\n",
    "from mmdet.models import build_detector\n",
    "from mmdet.apis import train_detector\n",
    "from mmdet.datasets import (build_dataloader, build_dataset, replace_ImageToTensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#config file 불러오기\n",
    "# cfg = Config.fromfile('/opt/ml/CustomPipeline/baseline/mmdetection/configs/faster_rcnn/faster_rcnn_r50_caffe_fpn_1x_coco.py')\n",
    "cfg = Config.fromfile('/opt/ml/CustomPipeline/baseline/mmdetection/configs/detr/detr_r50_8x2_150e_coco.py')\n",
    "\n",
    "classes = (\"General trash\",\"Paper\",\"Papaer pack\",\"Metal\",\"Glass\",\n",
    "           \"Plastic\",\"Styrofoam\",\"Plastic bag\",\"Battery\",\"Clothing\")\n",
    "\n",
    "#dataset 바꾸기\n",
    "root = \"/opt/ml/detection/dataset/\"\n",
    "cfg.data.train.classes = classes\n",
    "cfg.data.train.img_prefix  = root\n",
    "cfg.data.train.ann_file = root + 'train.json'\n",
    "# cfg.data.train.pipeline[2]['img_scale'] = (1024,1024) # Resize\n",
    "\n",
    "cfg.data.val.classes = classes\n",
    "cfg.data.val.img_prefix  = root\n",
    "cfg.data.val.ann_file = root + 'test.json'\n",
    "# cfg.data.val.pipeline[1]['img_scale'] = (1024,1024) # Resize\n",
    "\n",
    "cfg.data.test.classes = classes\n",
    "cfg.data.test.img_prefix  = root\n",
    "cfg.data.test.ann_file = root + 'test.json'\n",
    "# cfg.data.test.pipeline[1]['img_scale'] = (1024,1024) # Resize\n",
    "\n",
    "cfg.data.samples_per_gpu = 4\n",
    "cfg.data.workers_per_gpu = 4\n",
    "cfg.seed= 42\n",
    "cfg.gpu_ids = [0]\n",
    "cfg.work_dir = './work_dirs/detr_trash'\n",
    "\n",
    "# cfg.model.roi_head.bbox_head.num_classes = 11\n",
    "cfg.model.bbox_head.num_classes = 10\n",
    "cfg.optimizer_config.grad_clip = dict(max_norm=35,norm_type=2)\n",
    "cfg.checkpoint_config = dict(max_keep_ckpts=3,interval=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.20s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-27 08:11:09,884 - mmcv - INFO - initialize ResNet with init_cfg {'type': 'Pretrained', 'checkpoint': 'torchvision://resnet50'}\n",
      "2022-03-27 08:11:09,885 - mmcv - INFO - load model from: torchvision://resnet50\n",
      "2022-03-27 08:11:09,886 - mmcv - INFO - load checkpoint from torchvision path: torchvision://resnet50\n",
      "2022-03-27 08:11:10,095 - mmcv - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: fc.weight, fc.bias\n",
      "\n",
      "2022-03-27 08:11:10,232 - mmcv - INFO - \n",
      "backbone.conv1.weight - torch.Size([64, 3, 7, 7]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,234 - mmcv - INFO - \n",
      "backbone.bn1.weight - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,234 - mmcv - INFO - \n",
      "backbone.bn1.bias - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,235 - mmcv - INFO - \n",
      "backbone.layer1.0.conv1.weight - torch.Size([64, 64, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,236 - mmcv - INFO - \n",
      "backbone.layer1.0.bn1.weight - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,236 - mmcv - INFO - \n",
      "backbone.layer1.0.bn1.bias - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,237 - mmcv - INFO - \n",
      "backbone.layer1.0.conv2.weight - torch.Size([64, 64, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,237 - mmcv - INFO - \n",
      "backbone.layer1.0.bn2.weight - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,238 - mmcv - INFO - \n",
      "backbone.layer1.0.bn2.bias - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,239 - mmcv - INFO - \n",
      "backbone.layer1.0.conv3.weight - torch.Size([256, 64, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,239 - mmcv - INFO - \n",
      "backbone.layer1.0.bn3.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,240 - mmcv - INFO - \n",
      "backbone.layer1.0.bn3.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,241 - mmcv - INFO - \n",
      "backbone.layer1.0.downsample.0.weight - torch.Size([256, 64, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,241 - mmcv - INFO - \n",
      "backbone.layer1.0.downsample.1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,242 - mmcv - INFO - \n",
      "backbone.layer1.0.downsample.1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,242 - mmcv - INFO - \n",
      "backbone.layer1.1.conv1.weight - torch.Size([64, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,243 - mmcv - INFO - \n",
      "backbone.layer1.1.bn1.weight - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,244 - mmcv - INFO - \n",
      "backbone.layer1.1.bn1.bias - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,244 - mmcv - INFO - \n",
      "backbone.layer1.1.conv2.weight - torch.Size([64, 64, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,246 - mmcv - INFO - \n",
      "backbone.layer1.1.bn2.weight - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,248 - mmcv - INFO - \n",
      "backbone.layer1.1.bn2.bias - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,249 - mmcv - INFO - \n",
      "backbone.layer1.1.conv3.weight - torch.Size([256, 64, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,250 - mmcv - INFO - \n",
      "backbone.layer1.1.bn3.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,250 - mmcv - INFO - \n",
      "backbone.layer1.1.bn3.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,251 - mmcv - INFO - \n",
      "backbone.layer1.2.conv1.weight - torch.Size([64, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,252 - mmcv - INFO - \n",
      "backbone.layer1.2.bn1.weight - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,252 - mmcv - INFO - \n",
      "backbone.layer1.2.bn1.bias - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,253 - mmcv - INFO - \n",
      "backbone.layer1.2.conv2.weight - torch.Size([64, 64, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,254 - mmcv - INFO - \n",
      "backbone.layer1.2.bn2.weight - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,254 - mmcv - INFO - \n",
      "backbone.layer1.2.bn2.bias - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,255 - mmcv - INFO - \n",
      "backbone.layer1.2.conv3.weight - torch.Size([256, 64, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,255 - mmcv - INFO - \n",
      "backbone.layer1.2.bn3.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,256 - mmcv - INFO - \n",
      "backbone.layer1.2.bn3.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,257 - mmcv - INFO - \n",
      "backbone.layer2.0.conv1.weight - torch.Size([128, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,257 - mmcv - INFO - \n",
      "backbone.layer2.0.bn1.weight - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,258 - mmcv - INFO - \n",
      "backbone.layer2.0.bn1.bias - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,258 - mmcv - INFO - \n",
      "backbone.layer2.0.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,259 - mmcv - INFO - \n",
      "backbone.layer2.0.bn2.weight - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,260 - mmcv - INFO - \n",
      "backbone.layer2.0.bn2.bias - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,260 - mmcv - INFO - \n",
      "backbone.layer2.0.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,261 - mmcv - INFO - \n",
      "backbone.layer2.0.bn3.weight - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,262 - mmcv - INFO - \n",
      "backbone.layer2.0.bn3.bias - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,262 - mmcv - INFO - \n",
      "backbone.layer2.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,263 - mmcv - INFO - \n",
      "backbone.layer2.0.downsample.1.weight - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,263 - mmcv - INFO - \n",
      "backbone.layer2.0.downsample.1.bias - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,264 - mmcv - INFO - \n",
      "backbone.layer2.1.conv1.weight - torch.Size([128, 512, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,265 - mmcv - INFO - \n",
      "backbone.layer2.1.bn1.weight - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,265 - mmcv - INFO - \n",
      "backbone.layer2.1.bn1.bias - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,266 - mmcv - INFO - \n",
      "backbone.layer2.1.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,266 - mmcv - INFO - \n",
      "backbone.layer2.1.bn2.weight - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,267 - mmcv - INFO - \n",
      "backbone.layer2.1.bn2.bias - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,267 - mmcv - INFO - \n",
      "backbone.layer2.1.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,268 - mmcv - INFO - \n",
      "backbone.layer2.1.bn3.weight - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,268 - mmcv - INFO - \n",
      "backbone.layer2.1.bn3.bias - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,269 - mmcv - INFO - \n",
      "backbone.layer2.2.conv1.weight - torch.Size([128, 512, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,269 - mmcv - INFO - \n",
      "backbone.layer2.2.bn1.weight - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,270 - mmcv - INFO - \n",
      "backbone.layer2.2.bn1.bias - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,270 - mmcv - INFO - \n",
      "backbone.layer2.2.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,271 - mmcv - INFO - \n",
      "backbone.layer2.2.bn2.weight - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,271 - mmcv - INFO - \n",
      "backbone.layer2.2.bn2.bias - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,272 - mmcv - INFO - \n",
      "backbone.layer2.2.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,272 - mmcv - INFO - \n",
      "backbone.layer2.2.bn3.weight - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,273 - mmcv - INFO - \n",
      "backbone.layer2.2.bn3.bias - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,273 - mmcv - INFO - \n",
      "backbone.layer2.3.conv1.weight - torch.Size([128, 512, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,274 - mmcv - INFO - \n",
      "backbone.layer2.3.bn1.weight - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,274 - mmcv - INFO - \n",
      "backbone.layer2.3.bn1.bias - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,275 - mmcv - INFO - \n",
      "backbone.layer2.3.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,275 - mmcv - INFO - \n",
      "backbone.layer2.3.bn2.weight - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,276 - mmcv - INFO - \n",
      "backbone.layer2.3.bn2.bias - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,276 - mmcv - INFO - \n",
      "backbone.layer2.3.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,276 - mmcv - INFO - \n",
      "backbone.layer2.3.bn3.weight - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,277 - mmcv - INFO - \n",
      "backbone.layer2.3.bn3.bias - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,277 - mmcv - INFO - \n",
      "backbone.layer3.0.conv1.weight - torch.Size([256, 512, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,278 - mmcv - INFO - \n",
      "backbone.layer3.0.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,278 - mmcv - INFO - \n",
      "backbone.layer3.0.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,279 - mmcv - INFO - \n",
      "backbone.layer3.0.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,279 - mmcv - INFO - \n",
      "backbone.layer3.0.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,280 - mmcv - INFO - \n",
      "backbone.layer3.0.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,280 - mmcv - INFO - \n",
      "backbone.layer3.0.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,281 - mmcv - INFO - \n",
      "backbone.layer3.0.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,281 - mmcv - INFO - \n",
      "backbone.layer3.0.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,281 - mmcv - INFO - \n",
      "backbone.layer3.0.downsample.0.weight - torch.Size([1024, 512, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,282 - mmcv - INFO - \n",
      "backbone.layer3.0.downsample.1.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,282 - mmcv - INFO - \n",
      "backbone.layer3.0.downsample.1.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,283 - mmcv - INFO - \n",
      "backbone.layer3.1.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,283 - mmcv - INFO - \n",
      "backbone.layer3.1.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,284 - mmcv - INFO - \n",
      "backbone.layer3.1.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,284 - mmcv - INFO - \n",
      "backbone.layer3.1.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,284 - mmcv - INFO - \n",
      "backbone.layer3.1.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,285 - mmcv - INFO - \n",
      "backbone.layer3.1.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,286 - mmcv - INFO - \n",
      "backbone.layer3.1.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,286 - mmcv - INFO - \n",
      "backbone.layer3.1.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,287 - mmcv - INFO - \n",
      "backbone.layer3.1.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,287 - mmcv - INFO - \n",
      "backbone.layer3.2.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,287 - mmcv - INFO - \n",
      "backbone.layer3.2.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,288 - mmcv - INFO - \n",
      "backbone.layer3.2.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,288 - mmcv - INFO - \n",
      "backbone.layer3.2.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,289 - mmcv - INFO - \n",
      "backbone.layer3.2.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,289 - mmcv - INFO - \n",
      "backbone.layer3.2.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,290 - mmcv - INFO - \n",
      "backbone.layer3.2.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,290 - mmcv - INFO - \n",
      "backbone.layer3.2.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,291 - mmcv - INFO - \n",
      "backbone.layer3.2.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,291 - mmcv - INFO - \n",
      "backbone.layer3.3.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,291 - mmcv - INFO - \n",
      "backbone.layer3.3.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,292 - mmcv - INFO - \n",
      "backbone.layer3.3.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,292 - mmcv - INFO - \n",
      "backbone.layer3.3.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,293 - mmcv - INFO - \n",
      "backbone.layer3.3.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,293 - mmcv - INFO - \n",
      "backbone.layer3.3.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,294 - mmcv - INFO - \n",
      "backbone.layer3.3.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,294 - mmcv - INFO - \n",
      "backbone.layer3.3.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,295 - mmcv - INFO - \n",
      "backbone.layer3.3.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,295 - mmcv - INFO - \n",
      "backbone.layer3.4.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,295 - mmcv - INFO - \n",
      "backbone.layer3.4.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,296 - mmcv - INFO - \n",
      "backbone.layer3.4.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,296 - mmcv - INFO - \n",
      "backbone.layer3.4.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,297 - mmcv - INFO - \n",
      "backbone.layer3.4.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,297 - mmcv - INFO - \n",
      "backbone.layer3.4.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,298 - mmcv - INFO - \n",
      "backbone.layer3.4.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,298 - mmcv - INFO - \n",
      "backbone.layer3.4.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,299 - mmcv - INFO - \n",
      "backbone.layer3.4.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,299 - mmcv - INFO - \n",
      "backbone.layer3.5.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,299 - mmcv - INFO - \n",
      "backbone.layer3.5.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,300 - mmcv - INFO - \n",
      "backbone.layer3.5.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,300 - mmcv - INFO - \n",
      "backbone.layer3.5.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,301 - mmcv - INFO - \n",
      "backbone.layer3.5.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,301 - mmcv - INFO - \n",
      "backbone.layer3.5.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,302 - mmcv - INFO - \n",
      "backbone.layer3.5.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,302 - mmcv - INFO - \n",
      "backbone.layer3.5.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,302 - mmcv - INFO - \n",
      "backbone.layer3.5.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,303 - mmcv - INFO - \n",
      "backbone.layer4.0.conv1.weight - torch.Size([512, 1024, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,303 - mmcv - INFO - \n",
      "backbone.layer4.0.bn1.weight - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,304 - mmcv - INFO - \n",
      "backbone.layer4.0.bn1.bias - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,304 - mmcv - INFO - \n",
      "backbone.layer4.0.conv2.weight - torch.Size([512, 512, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,305 - mmcv - INFO - \n",
      "backbone.layer4.0.bn2.weight - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,305 - mmcv - INFO - \n",
      "backbone.layer4.0.bn2.bias - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,306 - mmcv - INFO - \n",
      "backbone.layer4.0.conv3.weight - torch.Size([2048, 512, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,306 - mmcv - INFO - \n",
      "backbone.layer4.0.bn3.weight - torch.Size([2048]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,306 - mmcv - INFO - \n",
      "backbone.layer4.0.bn3.bias - torch.Size([2048]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,307 - mmcv - INFO - \n",
      "backbone.layer4.0.downsample.0.weight - torch.Size([2048, 1024, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,307 - mmcv - INFO - \n",
      "backbone.layer4.0.downsample.1.weight - torch.Size([2048]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,308 - mmcv - INFO - \n",
      "backbone.layer4.0.downsample.1.bias - torch.Size([2048]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,308 - mmcv - INFO - \n",
      "backbone.layer4.1.conv1.weight - torch.Size([512, 2048, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,309 - mmcv - INFO - \n",
      "backbone.layer4.1.bn1.weight - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,309 - mmcv - INFO - \n",
      "backbone.layer4.1.bn1.bias - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,309 - mmcv - INFO - \n",
      "backbone.layer4.1.conv2.weight - torch.Size([512, 512, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,310 - mmcv - INFO - \n",
      "backbone.layer4.1.bn2.weight - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,310 - mmcv - INFO - \n",
      "backbone.layer4.1.bn2.bias - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,311 - mmcv - INFO - \n",
      "backbone.layer4.1.conv3.weight - torch.Size([2048, 512, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,311 - mmcv - INFO - \n",
      "backbone.layer4.1.bn3.weight - torch.Size([2048]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,312 - mmcv - INFO - \n",
      "backbone.layer4.1.bn3.bias - torch.Size([2048]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,312 - mmcv - INFO - \n",
      "backbone.layer4.2.conv1.weight - torch.Size([512, 2048, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,313 - mmcv - INFO - \n",
      "backbone.layer4.2.bn1.weight - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,313 - mmcv - INFO - \n",
      "backbone.layer4.2.bn1.bias - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,313 - mmcv - INFO - \n",
      "backbone.layer4.2.conv2.weight - torch.Size([512, 512, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,314 - mmcv - INFO - \n",
      "backbone.layer4.2.bn2.weight - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,314 - mmcv - INFO - \n",
      "backbone.layer4.2.bn2.bias - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,315 - mmcv - INFO - \n",
      "backbone.layer4.2.conv3.weight - torch.Size([2048, 512, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,315 - mmcv - INFO - \n",
      "backbone.layer4.2.bn3.weight - torch.Size([2048]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,316 - mmcv - INFO - \n",
      "backbone.layer4.2.bn3.bias - torch.Size([2048]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2022-03-27 08:11:10,316 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.0.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,316 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.0.attentions.0.attn.in_proj_bias - torch.Size([768]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,317 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.0.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,317 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.0.attentions.0.attn.out_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,318 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.0.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,318 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.0.ffns.0.layers.0.0.bias - torch.Size([2048]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,319 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.0.ffns.0.layers.1.weight - torch.Size([256, 2048]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,319 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.0.ffns.0.layers.1.bias - torch.Size([256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,320 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.0.norms.0.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,320 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.0.norms.0.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,320 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.0.norms.1.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,321 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.0.norms.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,321 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.1.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,322 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.1.attentions.0.attn.in_proj_bias - torch.Size([768]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,322 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.1.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,323 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.1.attentions.0.attn.out_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,323 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.1.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,324 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.1.ffns.0.layers.0.0.bias - torch.Size([2048]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,324 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.1.ffns.0.layers.1.weight - torch.Size([256, 2048]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,325 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.1.ffns.0.layers.1.bias - torch.Size([256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,325 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.1.norms.0.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,325 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.1.norms.0.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,326 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.1.norms.1.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,326 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.1.norms.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,327 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.2.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,327 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.2.attentions.0.attn.in_proj_bias - torch.Size([768]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,328 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.2.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,328 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.2.attentions.0.attn.out_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,329 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.2.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,329 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.2.ffns.0.layers.0.0.bias - torch.Size([2048]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,329 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.2.ffns.0.layers.1.weight - torch.Size([256, 2048]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,330 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.2.ffns.0.layers.1.bias - torch.Size([256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,330 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.2.norms.0.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,331 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.2.norms.0.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,331 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.2.norms.1.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,332 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.2.norms.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,332 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.3.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,332 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.3.attentions.0.attn.in_proj_bias - torch.Size([768]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,333 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.3.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,333 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.3.attentions.0.attn.out_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,334 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.3.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,334 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.3.ffns.0.layers.0.0.bias - torch.Size([2048]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,335 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.3.ffns.0.layers.1.weight - torch.Size([256, 2048]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,335 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.3.ffns.0.layers.1.bias - torch.Size([256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,336 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.3.norms.0.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,336 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.3.norms.0.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,336 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.3.norms.1.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,337 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.3.norms.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,337 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.4.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,338 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.4.attentions.0.attn.in_proj_bias - torch.Size([768]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,338 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.4.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,339 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.4.attentions.0.attn.out_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,339 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.4.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,339 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.4.ffns.0.layers.0.0.bias - torch.Size([2048]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,340 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.4.ffns.0.layers.1.weight - torch.Size([256, 2048]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,340 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.4.ffns.0.layers.1.bias - torch.Size([256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,341 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.4.norms.0.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,341 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.4.norms.0.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,342 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.4.norms.1.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,342 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.4.norms.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,343 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.5.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,343 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.5.attentions.0.attn.in_proj_bias - torch.Size([768]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,344 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.5.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,344 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.5.attentions.0.attn.out_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,344 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.5.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,345 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.5.ffns.0.layers.0.0.bias - torch.Size([2048]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,345 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.5.ffns.0.layers.1.weight - torch.Size([256, 2048]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,346 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.5.ffns.0.layers.1.bias - torch.Size([256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,346 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.5.norms.0.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,347 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.5.norms.0.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,347 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.5.norms.1.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,348 - mmcv - INFO - \n",
      "bbox_head.transformer.encoder.layers.5.norms.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,348 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.0.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,349 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.0.attentions.0.attn.in_proj_bias - torch.Size([768]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,349 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.0.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,349 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.0.attentions.0.attn.out_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,350 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.0.attentions.1.attn.in_proj_weight - torch.Size([768, 256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,350 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.0.attentions.1.attn.in_proj_bias - torch.Size([768]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,351 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.0.attentions.1.attn.out_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,351 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.0.attentions.1.attn.out_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,352 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.0.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,352 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.0.ffns.0.layers.0.0.bias - torch.Size([2048]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,353 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.0.ffns.0.layers.1.weight - torch.Size([256, 2048]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,353 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.0.ffns.0.layers.1.bias - torch.Size([256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,354 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.0.norms.0.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,354 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.0.norms.0.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,355 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.0.norms.1.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,355 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.0.norms.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,356 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.0.norms.2.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,356 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.0.norms.2.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,356 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.1.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,357 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.1.attentions.0.attn.in_proj_bias - torch.Size([768]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,357 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.1.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,358 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.1.attentions.0.attn.out_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,358 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.1.attentions.1.attn.in_proj_weight - torch.Size([768, 256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,359 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.1.attentions.1.attn.in_proj_bias - torch.Size([768]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,360 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.1.attentions.1.attn.out_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,360 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.1.attentions.1.attn.out_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,361 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.1.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,361 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.1.ffns.0.layers.0.0.bias - torch.Size([2048]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,362 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.1.ffns.0.layers.1.weight - torch.Size([256, 2048]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,362 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.1.ffns.0.layers.1.bias - torch.Size([256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,363 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.1.norms.0.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,363 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.1.norms.0.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,363 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.1.norms.1.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,364 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.1.norms.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,364 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.1.norms.2.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,365 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.1.norms.2.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,365 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.2.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,366 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.2.attentions.0.attn.in_proj_bias - torch.Size([768]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,366 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.2.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,366 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.2.attentions.0.attn.out_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,367 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.2.attentions.1.attn.in_proj_weight - torch.Size([768, 256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,367 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.2.attentions.1.attn.in_proj_bias - torch.Size([768]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,368 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.2.attentions.1.attn.out_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,368 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.2.attentions.1.attn.out_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,369 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.2.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,369 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.2.ffns.0.layers.0.0.bias - torch.Size([2048]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,370 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.2.ffns.0.layers.1.weight - torch.Size([256, 2048]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,370 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.2.ffns.0.layers.1.bias - torch.Size([256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,371 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.2.norms.0.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,371 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.2.norms.0.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,371 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.2.norms.1.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,372 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.2.norms.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,372 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.2.norms.2.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,373 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.2.norms.2.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,373 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.3.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,374 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.3.attentions.0.attn.in_proj_bias - torch.Size([768]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,374 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.3.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,375 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.3.attentions.0.attn.out_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,375 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.3.attentions.1.attn.in_proj_weight - torch.Size([768, 256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,375 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.3.attentions.1.attn.in_proj_bias - torch.Size([768]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,376 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.3.attentions.1.attn.out_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,376 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.3.attentions.1.attn.out_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,377 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.3.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,377 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.3.ffns.0.layers.0.0.bias - torch.Size([2048]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,378 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.3.ffns.0.layers.1.weight - torch.Size([256, 2048]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,378 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.3.ffns.0.layers.1.bias - torch.Size([256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,379 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.3.norms.0.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,379 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.3.norms.0.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,379 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.3.norms.1.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,380 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.3.norms.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,380 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.3.norms.2.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,381 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.3.norms.2.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,381 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.4.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,382 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.4.attentions.0.attn.in_proj_bias - torch.Size([768]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,382 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.4.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,383 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.4.attentions.0.attn.out_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,383 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.4.attentions.1.attn.in_proj_weight - torch.Size([768, 256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,384 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.4.attentions.1.attn.in_proj_bias - torch.Size([768]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,384 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.4.attentions.1.attn.out_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,401 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.4.attentions.1.attn.out_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,402 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.4.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,403 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.4.ffns.0.layers.0.0.bias - torch.Size([2048]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,403 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.4.ffns.0.layers.1.weight - torch.Size([256, 2048]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,403 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.4.ffns.0.layers.1.bias - torch.Size([256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,404 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.4.norms.0.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,404 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.4.norms.0.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,410 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.4.norms.1.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,410 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.4.norms.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,411 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.4.norms.2.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,411 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.4.norms.2.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,412 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.5.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,412 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.5.attentions.0.attn.in_proj_bias - torch.Size([768]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,413 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.5.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,413 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.5.attentions.0.attn.out_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,413 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.5.attentions.1.attn.in_proj_weight - torch.Size([768, 256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,414 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.5.attentions.1.attn.in_proj_bias - torch.Size([768]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,414 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.5.attentions.1.attn.out_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,415 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.5.attentions.1.attn.out_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,415 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.5.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,416 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.5.ffns.0.layers.0.0.bias - torch.Size([2048]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,416 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.5.ffns.0.layers.1.weight - torch.Size([256, 2048]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,417 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.5.ffns.0.layers.1.bias - torch.Size([256]): \n",
      "Initialized by user-defined `init_weights` in DETRHead  \n",
      " \n",
      "2022-03-27 08:11:10,417 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.5.norms.0.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,417 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.5.norms.0.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,418 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.5.norms.1.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,418 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.5.norms.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,424 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.5.norms.2.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,424 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.layers.5.norms.2.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,425 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.post_norm.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,425 - mmcv - INFO - \n",
      "bbox_head.transformer.decoder.post_norm.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,426 - mmcv - INFO - \n",
      "bbox_head.input_proj.weight - torch.Size([256, 2048, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,426 - mmcv - INFO - \n",
      "bbox_head.input_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,427 - mmcv - INFO - \n",
      "bbox_head.fc_cls.weight - torch.Size([11, 256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,427 - mmcv - INFO - \n",
      "bbox_head.fc_cls.bias - torch.Size([11]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,427 - mmcv - INFO - \n",
      "bbox_head.reg_ffn.layers.0.0.weight - torch.Size([256, 256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,428 - mmcv - INFO - \n",
      "bbox_head.reg_ffn.layers.0.0.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,428 - mmcv - INFO - \n",
      "bbox_head.reg_ffn.layers.1.weight - torch.Size([256, 256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,429 - mmcv - INFO - \n",
      "bbox_head.reg_ffn.layers.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,429 - mmcv - INFO - \n",
      "bbox_head.fc_reg.weight - torch.Size([4, 256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,430 - mmcv - INFO - \n",
      "bbox_head.fc_reg.bias - torch.Size([4]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n",
      "2022-03-27 08:11:10,430 - mmcv - INFO - \n",
      "bbox_head.query_embedding.weight - torch.Size([100, 256]): \n",
      "The value is the same before and after calling `init_weights` of DETR  \n",
      " \n"
     ]
    }
   ],
   "source": [
    "datasets = [build_dataset(cfg.data.train)]\n",
    "model = build_detector(cfg.model)\n",
    "model.init_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       " CocoDataset Train dataset with number of images 4693, and instance counts: \n",
       " +-------------------+-------+---------------+-------+-----------------+-------+-------------+-------+--------------+-------+\n",
       " | category          | count | category      | count | category        | count | category    | count | category     | count |\n",
       " +-------------------+-------+---------------+-------+-----------------+-------+-------------+-------+--------------+-------+\n",
       " | 0 [General trash] | 3965  | 1 [Paper]     | 6352  | 2 [Papaer pack] | 936   | 3 [Metal]   | 982   | 4 [Glass]    | 2943  |\n",
       " | 5 [Plastic]       | 1263  | 6 [Styrofoam] | 5178  | 7 [Plastic bag] | 159   | 8 [Battery] | 468   | 9 [Clothing] | 0     |\n",
       " +-------------------+-------+---------------+-------+-----------------+-------+-------------+-------+--------------+-------+]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 18:09:22,945 - mmdet - INFO - Start running, host: root@9075f89f9a55, work_dir: /opt/ml/CustomPipeline/MyModel/work_dirs/detr_trash\n",
      "2022-03-26 18:09:22,946 - mmdet - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) NumClassCheckHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(ABOVE_NORMAL) OptimizerHook                      \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) NumClassCheckHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_run:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "2022-03-26 18:09:22,947 - mmdet - INFO - workflow: [('train', 1)], max: 150 epochs\n",
      "2022-03-26 18:09:22,948 - mmdet - INFO - Checkpoints will be saved to /opt/ml/CustomPipeline/MyModel/work_dirs/detr_trash by HardDiskBackend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/ml/detection/baseline/mmdetection/mmdet/models/losses/cross_entropy_loss.py:239: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
      "  self.class_weight, device=cls_score.device)\n",
      "2022-03-26 18:09:44,440 - mmdet - INFO - Epoch [1][50/1174]\tlr: 1.000e-04, eta: 21:00:47, time: 0.430, data_time: 0.056, memory: 6414, loss_cls: 1.2723, loss_bbox: 3.2939, loss_iou: 2.0731, d0.loss_cls: 1.2485, d0.loss_bbox: 3.2975, d0.loss_iou: 2.0651, d1.loss_cls: 1.2604, d1.loss_bbox: 3.2869, d1.loss_iou: 2.0797, d2.loss_cls: 1.2594, d2.loss_bbox: 3.3043, d2.loss_iou: 2.0816, d3.loss_cls: 1.2654, d3.loss_bbox: 3.3060, d3.loss_iou: 2.0791, d4.loss_cls: 1.2536, d4.loss_bbox: 3.3043, d4.loss_iou: 2.0827, loss: 39.8137, grad_norm: 123.8499\n",
      "2022-03-26 18:10:02,426 - mmdet - INFO - Epoch [1][100/1174]\tlr: 1.000e-04, eta: 19:17:47, time: 0.360, data_time: 0.008, memory: 6414, loss_cls: 1.1860, loss_bbox: 3.1080, loss_iou: 2.0748, d0.loss_cls: 1.1559, d0.loss_bbox: 3.0467, d0.loss_iou: 1.9936, d1.loss_cls: 1.1714, d1.loss_bbox: 3.0440, d1.loss_iou: 2.0222, d2.loss_cls: 1.1755, d2.loss_bbox: 3.1106, d2.loss_iou: 2.0696, d3.loss_cls: 1.1737, d3.loss_bbox: 3.1294, d3.loss_iou: 2.0866, d4.loss_cls: 1.1766, d4.loss_bbox: 3.1611, d4.loss_iou: 2.0770, loss: 37.9627, grad_norm: 120.7741\n",
      "2022-03-26 18:10:20,690 - mmdet - INFO - Epoch [1][150/1174]\tlr: 1.000e-04, eta: 18:48:41, time: 0.365, data_time: 0.008, memory: 6414, loss_cls: 1.0787, loss_bbox: 2.5166, loss_iou: 1.6984, d0.loss_cls: 1.0600, d0.loss_bbox: 2.5119, d0.loss_iou: 1.6663, d1.loss_cls: 1.0917, d1.loss_bbox: 2.4065, d1.loss_iou: 1.5973, d2.loss_cls: 1.0825, d2.loss_bbox: 2.4304, d2.loss_iou: 1.6187, d3.loss_cls: 1.0818, d3.loss_bbox: 2.4785, d3.loss_iou: 1.6743, d4.loss_cls: 1.0679, d4.loss_bbox: 2.5724, d4.loss_iou: 1.7174, loss: 31.3512, grad_norm: 248.3986\n",
      "2022-03-26 18:10:38,423 - mmdet - INFO - Epoch [1][200/1174]\tlr: 1.000e-04, eta: 18:26:12, time: 0.355, data_time: 0.008, memory: 6414, loss_cls: 1.1856, loss_bbox: 2.1772, loss_iou: 1.4978, d0.loss_cls: 1.1418, d0.loss_bbox: 2.2825, d0.loss_iou: 1.5619, d1.loss_cls: 1.2005, d1.loss_bbox: 2.2130, d1.loss_iou: 1.4809, d2.loss_cls: 1.2128, d2.loss_bbox: 2.2447, d2.loss_iou: 1.4879, d3.loss_cls: 1.1975, d3.loss_bbox: 2.2313, d3.loss_iou: 1.4907, d4.loss_cls: 1.1663, d4.loss_bbox: 2.2652, d4.loss_iou: 1.5280, loss: 29.5657, grad_norm: 318.4051\n",
      "2022-03-26 18:10:55,563 - mmdet - INFO - Epoch [1][250/1174]\tlr: 1.000e-04, eta: 18:05:38, time: 0.343, data_time: 0.007, memory: 6527, loss_cls: 1.1944, loss_bbox: 2.1846, loss_iou: 1.5855, d0.loss_cls: 1.1805, d0.loss_bbox: 2.2525, d0.loss_iou: 1.6213, d1.loss_cls: 1.2350, d1.loss_bbox: 2.1759, d1.loss_iou: 1.5493, d2.loss_cls: 1.2323, d2.loss_bbox: 2.2240, d2.loss_iou: 1.5467, d3.loss_cls: 1.2348, d3.loss_bbox: 2.1926, d3.loss_iou: 1.5416, d4.loss_cls: 1.2081, d4.loss_bbox: 2.1889, d4.loss_iou: 1.5388, loss: 29.8869, grad_norm: 306.5959\n",
      "2022-03-26 18:11:13,342 - mmdet - INFO - Epoch [1][300/1174]\tlr: 1.000e-04, eta: 17:58:04, time: 0.356, data_time: 0.008, memory: 6621, loss_cls: 1.1900, loss_bbox: 2.2159, loss_iou: 1.5095, d0.loss_cls: 1.1816, d0.loss_bbox: 2.0887, d0.loss_iou: 1.5437, d1.loss_cls: 1.2014, d1.loss_bbox: 1.9884, d1.loss_iou: 1.4647, d2.loss_cls: 1.2007, d2.loss_bbox: 2.0710, d2.loss_iou: 1.5008, d3.loss_cls: 1.2162, d3.loss_bbox: 2.2071, d3.loss_iou: 1.5273, d4.loss_cls: 1.1938, d4.loss_bbox: 2.2198, d4.loss_iou: 1.5080, loss: 29.0288, grad_norm: 303.6011\n",
      "2022-03-26 18:11:30,856 - mmdet - INFO - Epoch [1][350/1174]\tlr: 1.000e-04, eta: 17:50:22, time: 0.350, data_time: 0.008, memory: 6621, loss_cls: 1.1455, loss_bbox: 1.8149, loss_iou: 1.4898, d0.loss_cls: 1.1403, d0.loss_bbox: 1.7716, d0.loss_iou: 1.5103, d1.loss_cls: 1.1652, d1.loss_bbox: 1.5288, d1.loss_iou: 1.3791, d2.loss_cls: 1.1673, d2.loss_bbox: 1.5025, d2.loss_iou: 1.3972, d3.loss_cls: 1.1581, d3.loss_bbox: 1.5888, d3.loss_iou: 1.3939, d4.loss_cls: 1.1466, d4.loss_bbox: 1.7148, d4.loss_iou: 1.4062, loss: 25.4207, grad_norm: 306.6476\n",
      "2022-03-26 18:11:48,410 - mmdet - INFO - Epoch [1][400/1174]\tlr: 1.000e-04, eta: 17:44:48, time: 0.351, data_time: 0.008, memory: 6621, loss_cls: 1.1154, loss_bbox: 1.5622, loss_iou: 1.4809, d0.loss_cls: 1.1138, d0.loss_bbox: 1.6298, d0.loss_iou: 1.5101, d1.loss_cls: 1.1296, d1.loss_bbox: 1.5506, d1.loss_iou: 1.4818, d2.loss_cls: 1.1194, d2.loss_bbox: 1.4870, d2.loss_iou: 1.4627, d3.loss_cls: 1.1165, d3.loss_bbox: 1.4926, d3.loss_iou: 1.4406, d4.loss_cls: 1.1081, d4.loss_bbox: 1.5347, d4.loss_iou: 1.4636, loss: 24.7994, grad_norm: 289.1170\n",
      "2022-03-26 18:12:06,786 - mmdet - INFO - Epoch [1][450/1174]\tlr: 1.000e-04, eta: 17:45:46, time: 0.368, data_time: 0.008, memory: 6912, loss_cls: 1.1577, loss_bbox: 1.5341, loss_iou: 1.5092, d0.loss_cls: 1.1231, d0.loss_bbox: 1.5752, d0.loss_iou: 1.4767, d1.loss_cls: 1.1583, d1.loss_bbox: 1.5121, d1.loss_iou: 1.4641, d2.loss_cls: 1.1484, d2.loss_bbox: 1.4938, d2.loss_iou: 1.4907, d3.loss_cls: 1.1436, d3.loss_bbox: 1.4586, d3.loss_iou: 1.4634, d4.loss_cls: 1.1513, d4.loss_bbox: 1.4622, d4.loss_iou: 1.4547, loss: 24.7774, grad_norm: 273.1062\n",
      "2022-03-26 18:12:24,300 - mmdet - INFO - Epoch [1][500/1174]\tlr: 1.000e-04, eta: 17:41:26, time: 0.350, data_time: 0.008, memory: 6912, loss_cls: 1.2071, loss_bbox: 1.5153, loss_iou: 1.4619, d0.loss_cls: 1.1758, d0.loss_bbox: 1.5772, d0.loss_iou: 1.4788, d1.loss_cls: 1.2052, d1.loss_bbox: 1.4853, d1.loss_iou: 1.4576, d2.loss_cls: 1.2105, d2.loss_bbox: 1.4403, d2.loss_iou: 1.4249, d3.loss_cls: 1.2189, d3.loss_bbox: 1.4744, d3.loss_iou: 1.4275, d4.loss_cls: 1.2237, d4.loss_bbox: 1.4819, d4.loss_iou: 1.4372, loss: 24.9038, grad_norm: 213.6167\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13622/2078669599.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_detector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/detection/baseline/mmdetection/mmdet/apis/train.py\u001b[0m in \u001b[0;36mtrain_detector\u001b[0;34m(model, dataset, cfg, distributed, validate, timestamp, meta)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m     \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkflow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/detection/lib/python3.7/site-packages/mmcv/runner/epoch_based_runner.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data_loaders, workflow, max_epochs, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_epochs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                     \u001b[0mepoch_runner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# wait for some hooks like loggers to finish\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/detection/lib/python3.7/site-packages/mmcv/runner/epoch_based_runner.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data_loader, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inner_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'before_train_iter'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_train_iter'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/detection/lib/python3.7/site-packages/mmcv/runner/epoch_based_runner.py\u001b[0m in \u001b[0;36mrun_iter\u001b[0;34m(self, data_batch, train_mode, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtrain_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             outputs = self.model.train_step(data_batch, self.optimizer,\n\u001b[0;32m---> 30\u001b[0;31m                                             **kwargs)\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/detection/lib/python3.7/site-packages/mmcv/parallel/data_parallel.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m                     f'found one of them on device: {t.device}')\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/detection/lib/python3.7/site-packages/mmcv/parallel/data_parallel.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(self, inputs, kwargs, device_ids)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mscatter_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/detection/lib/python3.7/site-packages/mmcv/parallel/scatter_gather.py\u001b[0m in \u001b[0;36mscatter_kwargs\u001b[0;34m(inputs, kwargs, target_gpus, dim)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mscatter_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_gpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;34m\"\"\"Scatter with support for kwargs dictionary.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_gpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_gpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/detection/lib/python3.7/site-packages/mmcv/parallel/scatter_gather.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(inputs, target_gpus, dim)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;31m# None, clearing the cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mscatter_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mscatter_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/detection/lib/python3.7/site-packages/mmcv/parallel/scatter_gather.py\u001b[0m in \u001b[0;36mscatter_map\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mScatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_gpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscatter_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscatter_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/detection/lib/python3.7/site-packages/mmcv/parallel/scatter_gather.py\u001b[0m in \u001b[0;36mscatter_map\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscatter_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtarget_gpus\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/detection/lib/python3.7/site-packages/mmcv/parallel/scatter_gather.py\u001b[0m in \u001b[0;36mscatter_map\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mScatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_gpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscatter_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscatter_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/detection/lib/python3.7/site-packages/mmcv/parallel/scatter_gather.py\u001b[0m in \u001b[0;36mscatter_map\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mScatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_gpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscatter_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/detection/lib/python3.7/site-packages/mmcv/parallel/_functions.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(target_gpus, input)\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mstreams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_get_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtarget_gpus\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_gpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstreams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Synchronize with the copy stream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstreams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/detection/lib/python3.7/site-packages/mmcv/parallel/_functions.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(input, devices, streams)\u001b[0m\n\u001b[1;32m     13\u001b[0m         outputs = [\n\u001b[1;32m     14\u001b[0m             scatter(input[i], [devices[i // chunk_size]],\n\u001b[0;32m---> 15\u001b[0;31m                     [streams[i // chunk_size]]) for i in range(len(input))\n\u001b[0m\u001b[1;32m     16\u001b[0m         ]\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/detection/lib/python3.7/site-packages/mmcv/parallel/_functions.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     13\u001b[0m         outputs = [\n\u001b[1;32m     14\u001b[0m             scatter(input[i], [devices[i // chunk_size]],\n\u001b[0;32m---> 15\u001b[0;31m                     [streams[i // chunk_size]]) for i in range(len(input))\n\u001b[0m\u001b[1;32m     16\u001b[0m         ]\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/detection/lib/python3.7/site-packages/mmcv/parallel/_functions.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(input, devices, streams)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdevices\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_detector(model,datasets[0],cfg,distributed=False,validate=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DETR(\n",
       "  (backbone): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): ResLayer(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): ResLayer(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): ResLayer(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): ResLayer(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  init_cfg={'type': 'Pretrained', 'checkpoint': 'torchvision://resnet50'}\n",
       "  (bbox_head): DETRHead(\n",
       "    (loss_cls): CrossEntropyLoss()\n",
       "    (loss_bbox): L1Loss()\n",
       "    (loss_iou): GIoULoss()\n",
       "    (activate): ReLU(inplace=True)\n",
       "    (positional_encoding): SinePositionalEncoding(num_feats=128, temperature=10000, normalize=True, scale=6.283185307179586, eps=1e-06)\n",
       "    (transformer): Transformer(\n",
       "      (encoder): DetrTransformerEncoder(\n",
       "        (layers): ModuleList(\n",
       "          (0): BaseTransformerLayer(\n",
       "            (attentions): ModuleList(\n",
       "              (0): MultiheadAttention(\n",
       "                (attn): MultiheadAttention(\n",
       "                  (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "                )\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (dropout_layer): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ffns): ModuleList(\n",
       "              (0): FFN(\n",
       "                (activate): ReLU(inplace=True)\n",
       "                (layers): Sequential(\n",
       "                  (0): Sequential(\n",
       "                    (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "                    (1): ReLU(inplace=True)\n",
       "                    (2): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "                  (2): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (dropout_layer): Identity()\n",
       "              )\n",
       "            )\n",
       "            (norms): ModuleList(\n",
       "              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (1): BaseTransformerLayer(\n",
       "            (attentions): ModuleList(\n",
       "              (0): MultiheadAttention(\n",
       "                (attn): MultiheadAttention(\n",
       "                  (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "                )\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (dropout_layer): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ffns): ModuleList(\n",
       "              (0): FFN(\n",
       "                (activate): ReLU(inplace=True)\n",
       "                (layers): Sequential(\n",
       "                  (0): Sequential(\n",
       "                    (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "                    (1): ReLU(inplace=True)\n",
       "                    (2): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "                  (2): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (dropout_layer): Identity()\n",
       "              )\n",
       "            )\n",
       "            (norms): ModuleList(\n",
       "              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (2): BaseTransformerLayer(\n",
       "            (attentions): ModuleList(\n",
       "              (0): MultiheadAttention(\n",
       "                (attn): MultiheadAttention(\n",
       "                  (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "                )\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (dropout_layer): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ffns): ModuleList(\n",
       "              (0): FFN(\n",
       "                (activate): ReLU(inplace=True)\n",
       "                (layers): Sequential(\n",
       "                  (0): Sequential(\n",
       "                    (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "                    (1): ReLU(inplace=True)\n",
       "                    (2): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "                  (2): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (dropout_layer): Identity()\n",
       "              )\n",
       "            )\n",
       "            (norms): ModuleList(\n",
       "              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (3): BaseTransformerLayer(\n",
       "            (attentions): ModuleList(\n",
       "              (0): MultiheadAttention(\n",
       "                (attn): MultiheadAttention(\n",
       "                  (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "                )\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (dropout_layer): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ffns): ModuleList(\n",
       "              (0): FFN(\n",
       "                (activate): ReLU(inplace=True)\n",
       "                (layers): Sequential(\n",
       "                  (0): Sequential(\n",
       "                    (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "                    (1): ReLU(inplace=True)\n",
       "                    (2): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "                  (2): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (dropout_layer): Identity()\n",
       "              )\n",
       "            )\n",
       "            (norms): ModuleList(\n",
       "              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (4): BaseTransformerLayer(\n",
       "            (attentions): ModuleList(\n",
       "              (0): MultiheadAttention(\n",
       "                (attn): MultiheadAttention(\n",
       "                  (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "                )\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (dropout_layer): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ffns): ModuleList(\n",
       "              (0): FFN(\n",
       "                (activate): ReLU(inplace=True)\n",
       "                (layers): Sequential(\n",
       "                  (0): Sequential(\n",
       "                    (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "                    (1): ReLU(inplace=True)\n",
       "                    (2): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "                  (2): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (dropout_layer): Identity()\n",
       "              )\n",
       "            )\n",
       "            (norms): ModuleList(\n",
       "              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (5): BaseTransformerLayer(\n",
       "            (attentions): ModuleList(\n",
       "              (0): MultiheadAttention(\n",
       "                (attn): MultiheadAttention(\n",
       "                  (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "                )\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (dropout_layer): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ffns): ModuleList(\n",
       "              (0): FFN(\n",
       "                (activate): ReLU(inplace=True)\n",
       "                (layers): Sequential(\n",
       "                  (0): Sequential(\n",
       "                    (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "                    (1): ReLU(inplace=True)\n",
       "                    (2): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "                  (2): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (dropout_layer): Identity()\n",
       "              )\n",
       "            )\n",
       "            (norms): ModuleList(\n",
       "              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (decoder): DetrTransformerDecoder(\n",
       "        (layers): ModuleList(\n",
       "          (0): DetrTransformerDecoderLayer(\n",
       "            (attentions): ModuleList(\n",
       "              (0): MultiheadAttention(\n",
       "                (attn): MultiheadAttention(\n",
       "                  (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "                )\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (dropout_layer): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (1): MultiheadAttention(\n",
       "                (attn): MultiheadAttention(\n",
       "                  (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "                )\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (dropout_layer): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ffns): ModuleList(\n",
       "              (0): FFN(\n",
       "                (activate): ReLU(inplace=True)\n",
       "                (layers): Sequential(\n",
       "                  (0): Sequential(\n",
       "                    (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "                    (1): ReLU(inplace=True)\n",
       "                    (2): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "                  (2): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (dropout_layer): Identity()\n",
       "              )\n",
       "            )\n",
       "            (norms): ModuleList(\n",
       "              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (1): DetrTransformerDecoderLayer(\n",
       "            (attentions): ModuleList(\n",
       "              (0): MultiheadAttention(\n",
       "                (attn): MultiheadAttention(\n",
       "                  (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "                )\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (dropout_layer): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (1): MultiheadAttention(\n",
       "                (attn): MultiheadAttention(\n",
       "                  (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "                )\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (dropout_layer): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ffns): ModuleList(\n",
       "              (0): FFN(\n",
       "                (activate): ReLU(inplace=True)\n",
       "                (layers): Sequential(\n",
       "                  (0): Sequential(\n",
       "                    (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "                    (1): ReLU(inplace=True)\n",
       "                    (2): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "                  (2): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (dropout_layer): Identity()\n",
       "              )\n",
       "            )\n",
       "            (norms): ModuleList(\n",
       "              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (2): DetrTransformerDecoderLayer(\n",
       "            (attentions): ModuleList(\n",
       "              (0): MultiheadAttention(\n",
       "                (attn): MultiheadAttention(\n",
       "                  (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "                )\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (dropout_layer): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (1): MultiheadAttention(\n",
       "                (attn): MultiheadAttention(\n",
       "                  (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "                )\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (dropout_layer): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ffns): ModuleList(\n",
       "              (0): FFN(\n",
       "                (activate): ReLU(inplace=True)\n",
       "                (layers): Sequential(\n",
       "                  (0): Sequential(\n",
       "                    (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "                    (1): ReLU(inplace=True)\n",
       "                    (2): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "                  (2): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (dropout_layer): Identity()\n",
       "              )\n",
       "            )\n",
       "            (norms): ModuleList(\n",
       "              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (3): DetrTransformerDecoderLayer(\n",
       "            (attentions): ModuleList(\n",
       "              (0): MultiheadAttention(\n",
       "                (attn): MultiheadAttention(\n",
       "                  (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "                )\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (dropout_layer): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (1): MultiheadAttention(\n",
       "                (attn): MultiheadAttention(\n",
       "                  (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "                )\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (dropout_layer): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ffns): ModuleList(\n",
       "              (0): FFN(\n",
       "                (activate): ReLU(inplace=True)\n",
       "                (layers): Sequential(\n",
       "                  (0): Sequential(\n",
       "                    (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "                    (1): ReLU(inplace=True)\n",
       "                    (2): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "                  (2): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (dropout_layer): Identity()\n",
       "              )\n",
       "            )\n",
       "            (norms): ModuleList(\n",
       "              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (4): DetrTransformerDecoderLayer(\n",
       "            (attentions): ModuleList(\n",
       "              (0): MultiheadAttention(\n",
       "                (attn): MultiheadAttention(\n",
       "                  (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "                )\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (dropout_layer): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (1): MultiheadAttention(\n",
       "                (attn): MultiheadAttention(\n",
       "                  (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "                )\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (dropout_layer): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ffns): ModuleList(\n",
       "              (0): FFN(\n",
       "                (activate): ReLU(inplace=True)\n",
       "                (layers): Sequential(\n",
       "                  (0): Sequential(\n",
       "                    (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "                    (1): ReLU(inplace=True)\n",
       "                    (2): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "                  (2): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (dropout_layer): Identity()\n",
       "              )\n",
       "            )\n",
       "            (norms): ModuleList(\n",
       "              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (5): DetrTransformerDecoderLayer(\n",
       "            (attentions): ModuleList(\n",
       "              (0): MultiheadAttention(\n",
       "                (attn): MultiheadAttention(\n",
       "                  (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "                )\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (dropout_layer): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (1): MultiheadAttention(\n",
       "                (attn): MultiheadAttention(\n",
       "                  (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "                )\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (dropout_layer): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ffns): ModuleList(\n",
       "              (0): FFN(\n",
       "                (activate): ReLU(inplace=True)\n",
       "                (layers): Sequential(\n",
       "                  (0): Sequential(\n",
       "                    (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "                    (1): ReLU(inplace=True)\n",
       "                    (2): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "                  (2): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (dropout_layer): Identity()\n",
       "              )\n",
       "            )\n",
       "            (norms): ModuleList(\n",
       "              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (post_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (input_proj): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (fc_cls): Linear(in_features=256, out_features=11, bias=True)\n",
       "    (reg_ffn): FFN(\n",
       "      (activate): ReLU(inplace=True)\n",
       "      (layers): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (dropout_layer): Identity()\n",
       "    )\n",
       "    (fc_reg): Linear(in_features=256, out_features=4, bias=True)\n",
       "    (query_embedding): Embedding(100, 256)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "dataset = [build_dataset(cfg.data.test)]\n",
    "data_loader = build_dataloader(\n",
    "        dataset,\n",
    "        samples_per_gpu=1,\n",
    "        workers_per_gpu=cfg.data.workers_per_gpu,\n",
    "        dist=False,\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "DETR: DETRHead: Expected class_weight to have type float. Found <class 'torch.Tensor'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/envs/detection/lib/python3.7/site-packages/mmcv/utils/registry.py\u001b[0m in \u001b[0;36mbuild_from_cfg\u001b[0;34m(cfg, registry, default_args)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/detection/baseline/mmdetection/mmdet/models/dense_heads/detr_head.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, num_classes, in_channels, num_query, num_reg_fcs, transformer, sync_cls_avg_factor, positional_encoding, loss_cls, loss_bbox, loss_iou, train_cfg, test_cfg, init_cfg, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclass_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mDETRHead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Expected '\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m                 \u001b[0;34m'class_weight to have type float. Found '\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Expected class_weight to have type float. Found <class 'torch.Tensor'>.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/envs/detection/lib/python3.7/site-packages/mmcv/utils/registry.py\u001b[0m in \u001b[0;36mbuild_from_cfg\u001b[0;34m(cfg, registry, default_args)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/detection/baseline/mmdetection/mmdet/models/detectors/detr.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, backbone, bbox_head, train_cfg, test_cfg, pretrained, init_cfg)\u001b[0m\n\u001b[1;32m     22\u001b[0m         super(DETR, self).__init__(backbone, None, bbox_head, train_cfg,\n\u001b[0;32m---> 23\u001b[0;31m                                    test_cfg, pretrained, init_cfg)\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/detection/baseline/mmdetection/mmdet/models/detectors/single_stage.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, backbone, neck, bbox_head, train_cfg, test_cfg, pretrained, init_cfg)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mbbox_head\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_cfg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_cfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbbox_head\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbbox_head\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_cfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_cfg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/detection/baseline/mmdetection/mmdet/models/builder.py\u001b[0m in \u001b[0;36mbuild_head\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;34m\"\"\"Build head.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mHEADS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/detection/lib/python3.7/site-packages/mmcv/utils/registry.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/detection/lib/python3.7/site-packages/mmcv/cnn/builder.py\u001b[0m in \u001b[0;36mbuild_model_from_cfg\u001b[0;34m(cfg, registry, default_args)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbuild_from_cfg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/detection/lib/python3.7/site-packages/mmcv/utils/registry.py\u001b[0m in \u001b[0;36mbuild_from_cfg\u001b[0;34m(cfg, registry, default_args)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m# Normal TypeError does not print class name.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{obj_cls.__name__}: {e}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: DETRHead: Expected class_weight to have type float. Found <class 'torch.Tensor'>.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9850/3712208004.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# checkpoint path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# checkpoint_path = os.path.join(cfg.work_dir, f'{epoch}.pth')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_detector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# build detector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# checkpoint = load_checkpoint(model, checkpoint_path, map_location='cpu') # ckpt load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/detection/baseline/mmdetection/mmdet/models/builder.py\u001b[0m in \u001b[0;36mbuild_detector\u001b[0;34m(cfg, train_cfg, test_cfg)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;34m'test_cfg specified in both outer field and model field '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     return DETECTORS.build(\n\u001b[0;32m---> 59\u001b[0;31m         cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/detection/lib/python3.7/site-packages/mmcv/utils/registry.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_add_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/detection/lib/python3.7/site-packages/mmcv/cnn/builder.py\u001b[0m in \u001b[0;36mbuild_model_from_cfg\u001b[0;34m(cfg, registry, default_args)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbuild_from_cfg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/detection/lib/python3.7/site-packages/mmcv/utils/registry.py\u001b[0m in \u001b[0;36mbuild_from_cfg\u001b[0;34m(cfg, registry, default_args)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m# Normal TypeError does not print class name.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{obj_cls.__name__}: {e}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: DETR: DETRHead: Expected class_weight to have type float. Found <class 'torch.Tensor'>."
     ]
    }
   ],
   "source": [
    "# epoch = 'latest'\n",
    "# checkpoint path\n",
    "# checkpoint_path = os.path.join(cfg.work_dir, f'{epoch}.pth')\n",
    "model = build_detector(cfg.model) # build detector\n",
    "# checkpoint = load_checkpoint(model, checkpoint_path, map_location='cpu') # ckpt load\n",
    "\n",
    "# model.CLASSES = dataset.CLASSES\n",
    "# model = MMDataParallel(model.cuda(), device_ids=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detection",
   "language": "python",
   "name": "detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
