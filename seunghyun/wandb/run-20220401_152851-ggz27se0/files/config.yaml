wandb_version: 1

_wandb:
  desc: null
  value:
    cli_version: 0.12.11
    framework: torch
    is_jupyter_run: false
    is_kaggle_kernel: false
    python_version: 3.7.11
    start_time: 1648826931
    t:
      1:
      - 1
      - 37
      - 38
      - 41
      2:
      - 1
      - 37
      - 38
      - 41
      3:
      - 13
      - 16
      4: 3.7.11
      5: 0.12.11
      8:
      - 5
albu_train_transforms:
  desc: null
  value:
  - interpolation: 1
    p: 0.5
    rotate_limit: 0
    scale_limit: 0.0
    shift_limit: 0.0625
    type: ShiftScaleRotate
  - brightness_limit:
    - 0.1
    - 0.3
    contrast_limit:
    - 0.1
    - 0.3
    p: 0.2
    type: RandomBrightnessContrast
  - p: 0.1
    transforms:
    - b_shift_limit: 10
      g_shift_limit: 10
      p: 1.0
      r_shift_limit: 10
      type: RGBShift
    - hue_shift_limit: 20
      p: 1.0
      sat_shift_limit: 30
      type: HueSaturationValue
      val_shift_limit: 20
    type: OneOf
  - p: 0.2
    quality_lower: 85
    quality_upper: 95
    type: JpegCompression
  - p: 0.1
    type: ChannelShuffle
  - p: 0.1
    transforms:
    - blur_limit: 3
      p: 1.0
      type: Blur
    - blur_limit: 3
      p: 1.0
      type: MedianBlur
    type: OneOf
checkpoint_config:
  desc: null
  value:
    interval: 1
    max_keep_ckpts: 1
    save_last: true
classes:
  desc: null
  value:
  - General trash
  - Paper
  - Paper pack
  - Metal
  - Glass
  - Plastic
  - Styrofoam
  - Plastic bag
  - Battery
  - Clothing
custom_hooks:
  desc: null
  value:
  - type: NumClassCheckHook
data:
  desc: null
  value:
    samples_per_gpu: 4
    test:
      ann_file: /opt/ml/detection/dataset/test.json
      img_prefix: /opt/ml/detection/dataset/
      pipeline:
      - type: LoadImageFromFile
      - flip: false
        img_scale:
        - 512
        - 512
        transforms:
        - keep_ratio: true
          type: Resize
        - type: RandomFlip
        - mean:
          - 123.6506697
          - 117.39730243
          - 110.07542563
          std:
          - 54.03457934
          - 53.36968771
          - 54.78390763
          to_rgb: true
          type: Normalize
        - size_divisor: 32
          type: Pad
        - keys:
          - img
          type: ImageToTensor
        - keys:
          - img
          type: Collect
        type: MultiScaleFlipAug
      type: CocoDataset
    train:
      ann_file: /opt/ml/detection/dataset/fold_0_train.json
      classes:
      - General trash
      - Paper
      - Paper pack
      - Metal
      - Glass
      - Plastic
      - Styrofoam
      - Plastic bag
      - Battery
      - Clothing
      img_prefix: /opt/ml/detection/dataset/
      pipeline:
      - img_scale:
        - 512
        - 512
        pad_val: 114.0
        type: Mosaic
      - border:
        - -256
        - -256
        scaling_ratio_range:
        - 0.1
        - 2
        type: RandomAffine
      - img_scale:
        - 512
        - 512
        pad_val: 114.0
        ratio_range:
        - 0.8
        - 1.6
        type: MixUp
      - type: LoadImageFromFile
      - type: LoadAnnotations
        with_bbox: true
      - img_scale:
        - 512
        - 512
        keep_ratio: true
        type: Resize
      - flip_ratio: 0.5
        type: RandomFlip
      - policies:
        - - img_scale:
            - - 512
              - 512
            - - 544
              - 544
            - - 576
              - 576
            - - 608
              - 608
            - - 640
              - 640
            - - 672
              - 672
            - - 704
              - 704
            - - 736
              - 736
            - - 768
              - 768
            - - 800
              - 800
            - - 832
              - 832
            - - 864
              - 864
            - - 896
              - 896
            - - 928
              - 928
            - - 960
              - 960
            - - 992
              - 992
            - - 1024
              - 1024
            keep_ratio: true
            multiscale_mode: value
            type: Resize
        - - img_scale:
            - - 400
              - 400
            - - 500
              - 500
            - - 600
              - 600
            keep_ratio: true
            multiscale_mode: value
            type: Resize
          - allow_negative_crop: true
            crop_size:
            - 384
            - 600
            crop_type: absolute_range
            type: RandomCrop
          - img_scale:
            - - 512
              - 512
            - - 544
              - 544
            - - 576
              - 576
            - - 608
              - 608
            - - 640
              - 640
            - - 672
              - 672
            - - 704
              - 704
            - - 736
              - 736
            - - 768
              - 768
            - - 800
              - 800
            - - 832
              - 832
            - - 864
              - 864
            - - 896
              - 896
            - - 928
              - 928
            - - 960
              - 960
            - - 992
              - 992
            - - 1024
              - 1024
            keep_ratio: true
            multiscale_mode: value
            override: true
            type: Resize
        type: AutoAugment
      - mean:
        - 123.6506697
        - 117.39730243
        - 110.07542563
        std:
        - 54.03457934
        - 53.36968771
        - 54.78390763
        to_rgb: true
        type: Normalize
      - size_divisor: 32
        type: Pad
      - bbox_params:
          filter_lost_elements: true
          format: pascal_voc
          label_fields:
          - gt_labels
          min_visibility: 0.0
          type: BboxParams
        keymap:
          gt_bboxes: bboxes
          img: image
        skip_img_without_anno: true
        transforms:
        - interpolation: 1
          p: 0.5
          rotate_limit: 0
          scale_limit: 0.0
          shift_limit: 0.0625
          type: ShiftScaleRotate
        - brightness_limit:
          - 0.1
          - 0.3
          contrast_limit:
          - 0.1
          - 0.3
          p: 0.2
          type: RandomBrightnessContrast
        - p: 0.1
          transforms:
          - b_shift_limit: 10
            g_shift_limit: 10
            p: 1.0
            r_shift_limit: 10
            type: RGBShift
          - hue_shift_limit: 20
            p: 1.0
            sat_shift_limit: 30
            type: HueSaturationValue
            val_shift_limit: 20
          type: OneOf
        - p: 0.2
          quality_lower: 85
          quality_upper: 95
          type: JpegCompression
        - p: 0.1
          type: ChannelShuffle
        - p: 0.1
          transforms:
          - blur_limit: 3
            p: 1.0
            type: Blur
          - blur_limit: 3
            p: 1.0
            type: MedianBlur
          type: OneOf
        type: Albu
        update_pad_shape: false
      - type: DefaultFormatBundle
      - keys:
        - img
        - gt_bboxes
        - gt_labels
        meta_keys:
        - filename
        - ori_shape
        - img_shape
        - img_norm_cfg
        - pad_shape
        - scale_factor
        type: Collect
      type: CocoDataset
    val:
      ann_file: /opt/ml/detection/dataset/fold_0_val.json
      classes:
      - General trash
      - Paper
      - Paper pack
      - Metal
      - Glass
      - Plastic
      - Styrofoam
      - Plastic bag
      - Battery
      - Clothing
      img_prefix: /opt/ml/detection/dataset/
      pipeline:
      - type: LoadImageFromFile
      - flip: false
        img_scale:
        - 512
        - 512
        transforms:
        - keep_ratio: true
          type: Resize
        - type: RandomFlip
        - mean:
          - 123.6506697
          - 117.39730243
          - 110.07542563
          std:
          - 54.03457934
          - 53.36968771
          - 54.78390763
          to_rgb: true
          type: Normalize
        - size_divisor: 32
          type: Pad
        - keys:
          - img
          type: ImageToTensor
        - keys:
          - img
          type: Collect
        type: MultiScaleFlipAug
      type: CocoDataset
    workers_per_gpu: 2
data_root:
  desc: null
  value: /opt/ml/detection/dataset/
dataset_type:
  desc: null
  value: CocoDataset
dist_params:
  desc: null
  value:
    backend: nccl
evaluation:
  desc: null
  value:
    classwise: true
    interval: 1
    metric: bbox
    save_best: bbox_mAP_50
img_norm_cfg:
  desc: null
  value:
    mean:
    - 123.6506697
    - 117.39730243
    - 110.07542563
    std:
    - 54.03457934
    - 53.36968771
    - 54.78390763
    to_rgb: true
img_scale:
  desc: null
  value:
  - 512
  - 512
load_from:
  desc: null
  value: null
log_config:
  desc: null
  value:
    hooks:
    - type: TextLoggerHook
    interval: 50
log_level:
  desc: null
  value: INFO
lr:
  desc: null
  value: 5.0e-05
lr_config:
  desc: null
  value:
    min_lr_ratio: 7.0e-06
    policy: CosineAnnealing
    warmup: linear
    warmup_iters: 300
    warmup_ratio: 0.1
model:
  desc: null
  value:
    backbone:
      depths:
      - 3
      - 3
      - 27
      - 3
      dims:
      - 192
      - 384
      - 768
      - 1536
      drop_path_rate: 0.2
      in_chans: 3
      init_cfg:
        checkpoint: https://dl.fbaipublicfiles.com/convnext/convnext_large_22k_224.pth
        type: Pretrained
      layer_scale_init_value: 1.0e-06
      out_indices:
      - 0
      - 1
      - 2
      - 3
      type: ConvNeXt
    neck:
      in_channels:
      - 192
      - 384
      - 768
      - 1536
      num_outs: 5
      out_channels: 256
      type: FPN
    roi_head:
      bbox_head:
      - bbox_coder:
          target_means:
          - 0.0
          - 0.0
          - 0.0
          - 0.0
          target_stds:
          - 0.1
          - 0.1
          - 0.2
          - 0.2
          type: DeltaXYWHBBoxCoder
        fc_out_channels: 1024
        in_channels: 256
        loss_bbox:
          beta: 1.0
          loss_weight: 1.0
          type: SmoothL1Loss
        loss_cls:
          loss_weight: 1.0
          type: CrossEntropyLoss
          use_sigmoid: false
        num_classes: 10
        reg_class_agnostic: true
        roi_feat_size: 7
        type: Shared2FCBBoxHead
      - bbox_coder:
          target_means:
          - 0.0
          - 0.0
          - 0.0
          - 0.0
          target_stds:
          - 0.05
          - 0.05
          - 0.1
          - 0.1
          type: DeltaXYWHBBoxCoder
        fc_out_channels: 1024
        in_channels: 256
        loss_bbox:
          beta: 1.0
          loss_weight: 1.0
          type: SmoothL1Loss
        loss_cls:
          loss_weight: 1.0
          type: CrossEntropyLoss
          use_sigmoid: false
        num_classes: 10
        reg_class_agnostic: true
        roi_feat_size: 7
        type: Shared2FCBBoxHead
      - bbox_coder:
          target_means:
          - 0.0
          - 0.0
          - 0.0
          - 0.0
          target_stds:
          - 0.033
          - 0.033
          - 0.067
          - 0.067
          type: DeltaXYWHBBoxCoder
        fc_out_channels: 1024
        in_channels: 256
        loss_bbox:
          beta: 1.0
          loss_weight: 1.0
          type: SmoothL1Loss
        loss_cls:
          loss_weight: 1.0
          type: CrossEntropyLoss
          use_sigmoid: false
        num_classes: 10
        reg_class_agnostic: true
        roi_feat_size: 7
        type: Shared2FCBBoxHead
      bbox_roi_extractor:
        featmap_strides:
        - 4
        - 8
        - 16
        - 32
        out_channels: 256
        roi_layer:
          output_size: 7
          sampling_ratio: 0
          type: RoIAlign
        type: SingleRoIExtractor
      num_stages: 3
      stage_loss_weights:
      - 1
      - 0.5
      - 0.25
      type: CascadeRoIHead
    rpn_head:
      anchor_generator:
        ratios:
        - 0.5
        - 1.0
        - 2.0
        scales:
        - 8
        strides:
        - 4
        - 8
        - 16
        - 32
        - 64
        type: AnchorGenerator
      bbox_coder:
        target_means:
        - 0.0
        - 0.0
        - 0.0
        - 0.0
        target_stds:
        - 1.0
        - 1.0
        - 1.0
        - 1.0
        type: DeltaXYWHBBoxCoder
      feat_channels: 256
      in_channels: 256
      loss_bbox:
        beta: 0.1111111111111111
        loss_weight: 1.0
        type: SmoothL1Loss
      loss_cls:
        loss_weight: 1.0
        type: CrossEntropyLoss
        use_sigmoid: true
      type: RPNHead
    test_cfg:
      rcnn:
        max_per_img: 100
        nms:
          iou_threshold: 0.5
          type: nms
        score_thr: 0.0
      rpn:
        max_per_img: 1000
        min_bbox_size: 0
        nms:
          iou_threshold: 0.7
          type: nms
        nms_pre: 1000
    train_cfg:
      rcnn:
      - assigner:
          ignore_iof_thr: -1
          match_low_quality: false
          min_pos_iou: 0.5
          neg_iou_thr: 0.5
          pos_iou_thr: 0.5
          type: MaxIoUAssigner
        debug: false
        pos_weight: -1
        sampler:
          add_gt_as_proposals: true
          neg_pos_ub: -1
          num: 512
          pos_fraction: 0.25
          type: RandomSampler
      - assigner:
          ignore_iof_thr: -1
          match_low_quality: false
          min_pos_iou: 0.6
          neg_iou_thr: 0.6
          pos_iou_thr: 0.6
          type: MaxIoUAssigner
        debug: false
        pos_weight: -1
        sampler:
          add_gt_as_proposals: true
          neg_pos_ub: -1
          num: 512
          pos_fraction: 0.25
          type: RandomSampler
      - assigner:
          ignore_iof_thr: -1
          match_low_quality: false
          min_pos_iou: 0.7
          neg_iou_thr: 0.7
          pos_iou_thr: 0.7
          type: MaxIoUAssigner
        debug: false
        pos_weight: -1
        sampler:
          add_gt_as_proposals: true
          neg_pos_ub: -1
          num: 512
          pos_fraction: 0.25
          type: RandomSampler
      rpn:
        allowed_border: 0
        assigner:
          ignore_iof_thr: -1
          match_low_quality: true
          min_pos_iou: 0.3
          neg_iou_thr: 0.3
          pos_iou_thr: 0.7
          type: MaxIoUAssigner
        debug: false
        pos_weight: -1
        sampler:
          add_gt_as_proposals: false
          neg_pos_ub: -1
          num: 256
          pos_fraction: 0.5
          type: RandomSampler
      rpn_proposal:
        max_per_img: 2000
        min_bbox_size: 0
        nms:
          iou_threshold: 0.7
          type: nms
        nms_pre: 2000
    type: CascadeRCNN
mp_start_method:
  desc: null
  value: fork
multi_scale:
  desc: null
  value:
  - - 512
    - 512
  - - 544
    - 544
  - - 576
    - 576
  - - 608
    - 608
  - - 640
    - 640
  - - 672
    - 672
  - - 704
    - 704
  - - 736
    - 736
  - - 768
    - 768
  - - 800
    - 800
  - - 832
    - 832
  - - 864
    - 864
  - - 896
    - 896
  - - 928
    - 928
  - - 960
    - 960
  - - 992
    - 992
  - - 1024
    - 1024
opencv_num_threads:
  desc: null
  value: 0
optimizer:
  desc: null
  value:
    lr: 5.0e-05
    type: AdamW
    weight_decay: 0.01
optimizer_config:
  desc: null
  value:
    grad_clip:
      max_norm: 10
      norm_type: 2
pretrained:
  desc: null
  value: https://dl.fbaipublicfiles.com/convnext/convnext_large_22k_224.pth
resume_from:
  desc: null
  value: null
runner:
  desc: null
  value:
    max_epochs: 12
    type: EpochBasedRunner
size_max:
  desc: null
  value: 1024
size_min:
  desc: null
  value: 512
test_pipeline:
  desc: null
  value:
  - type: LoadImageFromFile
  - flip: false
    img_scale:
    - 512
    - 512
    transforms:
    - keep_ratio: true
      type: Resize
    - type: RandomFlip
    - mean:
      - 123.6506697
      - 117.39730243
      - 110.07542563
      std:
      - 54.03457934
      - 53.36968771
      - 54.78390763
      to_rgb: true
      type: Normalize
    - size_divisor: 32
      type: Pad
    - keys:
      - img
      type: ImageToTensor
    - keys:
      - img
      type: Collect
    type: MultiScaleFlipAug
train_pipeline:
  desc: null
  value:
  - img_scale:
    - 512
    - 512
    pad_val: 114.0
    type: Mosaic
  - border:
    - -256
    - -256
    scaling_ratio_range:
    - 0.1
    - 2
    type: RandomAffine
  - img_scale:
    - 512
    - 512
    pad_val: 114.0
    ratio_range:
    - 0.8
    - 1.6
    type: MixUp
  - type: LoadImageFromFile
  - type: LoadAnnotations
    with_bbox: true
  - img_scale:
    - 512
    - 512
    keep_ratio: true
    type: Resize
  - flip_ratio: 0.5
    type: RandomFlip
  - policies:
    - - img_scale:
        - - 512
          - 512
        - - 544
          - 544
        - - 576
          - 576
        - - 608
          - 608
        - - 640
          - 640
        - - 672
          - 672
        - - 704
          - 704
        - - 736
          - 736
        - - 768
          - 768
        - - 800
          - 800
        - - 832
          - 832
        - - 864
          - 864
        - - 896
          - 896
        - - 928
          - 928
        - - 960
          - 960
        - - 992
          - 992
        - - 1024
          - 1024
        keep_ratio: true
        multiscale_mode: value
        type: Resize
    - - img_scale:
        - - 400
          - 400
        - - 500
          - 500
        - - 600
          - 600
        keep_ratio: true
        multiscale_mode: value
        type: Resize
      - allow_negative_crop: true
        crop_size:
        - 384
        - 600
        crop_type: absolute_range
        type: RandomCrop
      - img_scale:
        - - 512
          - 512
        - - 544
          - 544
        - - 576
          - 576
        - - 608
          - 608
        - - 640
          - 640
        - - 672
          - 672
        - - 704
          - 704
        - - 736
          - 736
        - - 768
          - 768
        - - 800
          - 800
        - - 832
          - 832
        - - 864
          - 864
        - - 896
          - 896
        - - 928
          - 928
        - - 960
          - 960
        - - 992
          - 992
        - - 1024
          - 1024
        keep_ratio: true
        multiscale_mode: value
        override: true
        type: Resize
    type: AutoAugment
  - mean:
    - 123.6506697
    - 117.39730243
    - 110.07542563
    std:
    - 54.03457934
    - 53.36968771
    - 54.78390763
    to_rgb: true
    type: Normalize
  - size_divisor: 32
    type: Pad
  - bbox_params:
      filter_lost_elements: true
      format: pascal_voc
      label_fields:
      - gt_labels
      min_visibility: 0.0
      type: BboxParams
    keymap:
      gt_bboxes: bboxes
      img: image
    skip_img_without_anno: true
    transforms:
    - interpolation: 1
      p: 0.5
      rotate_limit: 0
      scale_limit: 0.0
      shift_limit: 0.0625
      type: ShiftScaleRotate
    - brightness_limit:
      - 0.1
      - 0.3
      contrast_limit:
      - 0.1
      - 0.3
      p: 0.2
      type: RandomBrightnessContrast
    - p: 0.1
      transforms:
      - b_shift_limit: 10
        g_shift_limit: 10
        p: 1.0
        r_shift_limit: 10
        type: RGBShift
      - hue_shift_limit: 20
        p: 1.0
        sat_shift_limit: 30
        type: HueSaturationValue
        val_shift_limit: 20
      type: OneOf
    - p: 0.2
      quality_lower: 85
      quality_upper: 95
      type: JpegCompression
    - p: 0.1
      type: ChannelShuffle
    - p: 0.1
      transforms:
      - blur_limit: 3
        p: 1.0
        type: Blur
      - blur_limit: 3
        p: 1.0
        type: MedianBlur
      type: OneOf
    type: Albu
    update_pad_shape: false
  - type: DefaultFormatBundle
  - keys:
    - img
    - gt_bboxes
    - gt_labels
    meta_keys:
    - filename
    - ori_shape
    - img_shape
    - img_norm_cfg
    - pad_shape
    - scale_factor
    type: Collect
workflow:
  desc: null
  value:
  - - train
    - 1
